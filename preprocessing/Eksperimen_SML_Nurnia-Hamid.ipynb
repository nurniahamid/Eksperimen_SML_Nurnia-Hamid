{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kZLRMFl0JyyQ"
   },
   "source": [
    "# **1. Perkenalan Dataset**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hssSDn-5n3HR"
   },
   "source": [
    "Tahap pertama, Anda harus mencari dan menggunakan dataset dengan ketentuan sebagai berikut:\n",
    "\n",
    "1. **Sumber Dataset**:  \n",
    "   Dataset dapat diperoleh dari berbagai sumber, seperti public repositories (*Kaggle*, *UCI ML Repository*, *Open Data*) atau data primer yang Anda kumpulkan sendiri.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fKADPWcFKlj3"
   },
   "source": [
    "# **2. Import Library**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LgA3ERnVn84N"
   },
   "source": [
    "Pada tahap ini, Anda perlu mengimpor beberapa pustaka (library) Python yang dibutuhkan untuk analisis data dan pembangunan model machine learning atau deep learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import sklearn as sns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f3YIEnAFKrKL"
   },
   "source": [
    "# **3. Memuat Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ey3ItwTen_7E"
   },
   "source": [
    "Pada tahap ini, Anda perlu memuat dataset ke dalam notebook. Jika dataset dalam format CSV, Anda bisa menggunakan pustaka pandas untuk membacanya. Pastikan untuk mengecek beberapa baris awal dataset untuk memahami strukturnya dan memastikan data telah dimuat dengan benar.\n",
    "\n",
    "Jika dataset berada di Google Drive, pastikan Anda menghubungkan Google Drive ke Colab terlebih dahulu. Setelah dataset berhasil dimuat, langkah berikutnya adalah memeriksa kesesuaian data dan siap untuk dianalisis lebih lanjut.\n",
    "\n",
    "Jika dataset berupa unstructured data, silakan sesuaikan dengan format seperti kelas Machine Learning Pengembangan atau Machine Learning Terapan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "GHCGNTyrM5fS"
   },
   "outputs": [],
   "source": [
    "#Type your code here\n",
    "\n",
    "# load_iris adalah fungsi dari scikit-learn untuk memuat dataset Iris\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = load_iris(as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 baris pertama dataset mentah (df_raw):\n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                5.1               3.5                1.4               0.2   \n",
      "1                4.9               3.0                1.4               0.2   \n",
      "2                4.7               3.2                1.3               0.2   \n",
      "3                4.6               3.1                1.5               0.2   \n",
      "4                5.0               3.6                1.4               0.2   \n",
      "\n",
      "   target  \n",
      "0       0  \n",
      "1       0  \n",
      "2       0  \n",
      "3       0  \n",
      "4       0  \n"
     ]
    }
   ],
   "source": [
    "df_raw = iris_data.frame\n",
    "print(\"\\n5 baris pertama dataset mentah (df_raw):\")\n",
    "print(df_raw.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nama-nama kolom pada dataset:\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)', 'target']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nNama-nama kolom pada dataset:\")\n",
    "print(df_raw.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_raw_path = '../namadataset_raw/iris_mentah.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GALAT: Gagal menyimpan dataset mentah ke file: Cannot save file into a non-existent directory: '..\\namadataset_raw'\n",
      "Pastikan folder 'namadataset_raw' sudah ada di tingkat yang sama dengan folder 'preprocessing'.\n",
      "\n",
      "Dataset siap untuk EDA (Exploratory Data Analysis) dan Preprocessing.\n",
      "Bentuk DataFrame untuk EDA/Preprocessing: (150, 5)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Menggunakan df_raw.to_csv() untuk menyimpan DataFrame ke file CSV.\n",
    "    # index=False: Ini penting! Ini mencegah Pandas menulis indeks DataFrame (angka 0, 1, 2, ...)\n",
    "    #              sebagai kolom tambahan di dalam file CSV. Kita hanya ingin data aslinya.\n",
    "    df_raw.to_csv(output_raw_path, index=False)\n",
    "    print(f\"\\nDataset mentah Iris berhasil disimpan ke: {output_raw_path}\")\n",
    "    print(\"Silakan cek folder 'namadataset_raw' di File Explorer Anda.\")\n",
    "except Exception as e:\n",
    "    # Jika ada error saat menyimpan (misalnya folder 'namadataset_raw' belum ada),\n",
    "    # pesan error akan ditampilkan.\n",
    "    print(f\"\\nGALAT: Gagal menyimpan dataset mentah ke file: {e}\")\n",
    "    print(\"Pastikan folder 'namadataset_raw' sudah ada di tingkat yang sama dengan folder 'preprocessing'.\")\n",
    "\n",
    "# --- Bagian 3: Menyiapkan Data untuk EDA dan Preprocessing ---\n",
    "# Untuk menjaga keaslian df_raw, kita akan membuat salinannya untuk proses EDA dan preprocessing selanjutnya.\n",
    "# Ini adalah praktik terbaik agar Anda selalu punya data asli jika perlu merujuk kembali.\n",
    "df_eda = df_raw.copy()\n",
    "\n",
    "print(\"\\nDataset siap untuk EDA (Exploratory Data Analysis) dan Preprocessing.\")\n",
    "print(f\"Bentuk DataFrame untuk EDA/Preprocessing: {df_eda.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bgZkbJLpK9UR"
   },
   "source": [
    "# **4. Exploratory Data Analysis (EDA)**\n",
    "\n",
    "Pada tahap ini, Anda akan melakukan **Exploratory Data Analysis (EDA)** untuk memahami karakteristik dataset.\n",
    "\n",
    "Tujuan dari EDA adalah untuk memperoleh wawasan awal yang mendalam mengenai data dan menentukan langkah selanjutnya dalam analisis atau pemodelan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dKeejtvxM6X1"
   },
   "outputs": [],
   "source": [
    "#Type your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cpgHfgnSK3ip"
   },
   "source": [
    "# **5. Data Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "COf8KUPXLg5r"
   },
   "source": [
    "Pada tahap ini, data preprocessing adalah langkah penting untuk memastikan kualitas data sebelum digunakan dalam model machine learning.\n",
    "\n",
    "Jika Anda menggunakan data teks, data mentah sering kali mengandung nilai kosong, duplikasi, atau rentang nilai yang tidak konsisten, yang dapat memengaruhi kinerja model. Oleh karena itu, proses ini bertujuan untuk membersihkan dan mempersiapkan data agar analisis berjalan optimal.\n",
    "\n",
    "Berikut adalah tahapan-tahapan yang bisa dilakukan, tetapi **tidak terbatas** pada:\n",
    "1. Menghapus atau Menangani Data Kosong (Missing Values)\n",
    "2. Menghapus Data Duplikat\n",
    "3. Normalisasi atau Standarisasi Fitur\n",
    "4. Deteksi dan Penanganan Outlier\n",
    "5. Encoding Data Kategorikal\n",
    "6. Binning (Pengelompokan Data)\n",
    "\n",
    "Cukup sesuaikan dengan karakteristik data yang kamu gunakan yah. Khususnya ketika kami menggunakan data tidak terstruktur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Og8pGV0-iDLz"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
